"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.purgeCache = exports.storeCache = exports.invalidateEntries = exports.invalidateEntry = exports.resolveEntry = exports.InvalidCacheError = exports.getCacheIdentity = void 0;
const file_entry_cache_1 = __importDefault(require("file-entry-cache"));
const log_1 = require("./log");
const path_1 = __importDefault(require("path"));
const fs_1 = require("fs");
// we keep cache groups per entry file, to keep the cache free from override conflicts
const caches = {};
function getCacheIdentity(entry) {
    // don't use just the file name, the entry file can be the same, while the
    // overrides make it build target specific.
    const value = JSON.stringify(Object.assign(Object.assign({}, entry), { filepath: path_1.default.resolve(entry.file) }));
    return hash(value);
}
exports.getCacheIdentity = getCacheIdentity;
function getCache(identity) {
    if (caches[identity]) {
        return caches[identity];
    }
    caches[identity] = file_entry_cache_1.default.create(identity, path_1.default.resolve(process.cwd(), './node_modules/.cache/unimported'), true);
    return caches[identity];
}
// Create short hashes for file names
function hash(path) {
    let h;
    let i;
    for (h = 0, i = 0; i < path.length; h &= h) {
        h = 31 * h + path.charCodeAt(i++);
    }
    return Math.abs(h).toString(16);
}
class InvalidCacheError extends Error {
    constructor(message, path) {
        super(message);
        this.name = 'InvalidCacheError';
        this.path = path;
    }
    static wrap(e, path) {
        return new InvalidCacheError(e.message, path);
    }
}
exports.InvalidCacheError = InvalidCacheError;
function resolveEntry(path, generator, cacheIdentity = '*') {
    return __awaiter(this, void 0, void 0, function* () {
        const cacheEntry = getCache(cacheIdentity).getFileDescriptor(path);
        const meta = cacheEntry.meta;
        if (!meta) {
            // Something else referenced a now deleted file. Force error and let upstream handle
            throw new InvalidCacheError(`${path} was deleted`, path);
        }
        if (cacheEntry.changed || !meta.data) {
            meta.data = yield generator();
        }
        return meta.data;
    });
}
exports.resolveEntry = resolveEntry;
function invalidateEntry(path) {
    for (const cache of Object.values(caches)) {
        cache.removeEntry(path);
    }
}
exports.invalidateEntry = invalidateEntry;
function invalidateEntries(shouldRemove) {
    for (const cache of Object.values(caches)) {
        Object.values(cache.cache.all()).forEach((cacheEntry) => {
            if (shouldRemove(cacheEntry.data)) {
                cache.removeEntry(cacheEntry.data.path);
            }
        });
    }
}
exports.invalidateEntries = invalidateEntries;
function storeCache() {
    log_1.log.info('store cache');
    for (const key of Object.keys(caches)) {
        caches[key].reconcile();
    }
}
exports.storeCache = storeCache;
function purgeCache() {
    log_1.log.info('purge cache');
    (0, fs_1.rmSync)(path_1.default.resolve(process.cwd(), './node_modules/.cache/unimported'), {
        recursive: true,
        force: true,
    });
}
exports.purgeCache = purgeCache;
